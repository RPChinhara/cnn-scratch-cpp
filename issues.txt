- Move less when neutral and full is on (add energy as state)
- Try achieving open-endedness
- Change currentState to just state?
- Ask chathpt how energy should decrease
- Make headers again?
- Hunger and thirst states should have at least 10 levels?
- Add other entities coordinates as states?
- Add energy as states
- Get rewards if he gets closer to other entities?
- Get close to other entities once he’s within certain radius. It seems like people can see objects that are 3 miles away
- Change reward values from 1s
- Add other purposes other than eat and drink water as he has time and already neutral. Maybe, put him in modern society now ?, but waht about cat lol ?
- Both normdist and zeros are wrong so just use normdist?
- How many states do we have ask chathpt
- Add predators
- I need to save  the q table and use that for next training
- Hunger and thirat have more levels ? Like 0 to 50 at least?
- Watch discovru channels like what they do other than eating and drinking?
- Add sleep as a state like when ran out of energy? Why people sleep?
    - If action was sleep, sleep the program for like 8 hours? Yet, he might be eaten by predator if he wasn't sleeping on the bed/house.
- Add Mental state. People get sad when lonely. Interact with his friend
- How animal take care of hygine? Add hygine as state
    - wash himself with the water.
- Show chatGPT my code and ask wheather I could use pointer somewhere
- Add body and environment tempertures
- Should it grow like human? A Baby to an adult
- Log learning rate as well?
- Maybe study more about 脳科学? I feel like getting rewards system is related to this subject
- なぜルビーは走る
- Maybe there might be RL within Rl? e.g., within the states he decide to do puzzle game in order to learn new words at this point use another RL? I mean human is also like that meaning it’s like layers of RL. In order to live, you have to work, and within the work you have to do certatin tasks.
- Gets reward if he has done new things he hasn’t done before, but in order to do that maybe retreive some new words, or trend things from internet like news and create that environment so that he’s always going to experience new things.
- I need to make his eyes the idea is that whenever other entites are within certain pixels range add that entites coordinates as states that means states change dynamically, but this is same for us. We see things because we can see at that moment so our states changes also.
- How to solve the issue where he goes to place he already has been before
- I think I have to utilize done and total reward somehow. Maybe done once gets 10 minutes log rewards, and decides which parametes are best ?
- Learn 10 words using nested RL
- Add news, and nationality as states
- An agent should address new goals forever
- How to fix always choosing first Action in q learning choseAction() issue
- Turn functions relate in RL into cuda kernel if it's possible
- Change to friend from agent_2 ?
- When is condidered done ? When total reward is below certain threshold? After certain time has passed ? Because if I start new episode I could use updated q table.
- common value for exploration rate ? How should I decay them ?
- If collisions happen continuouslly, it only considers first one e.g., wall collisions.
- Refactor ResolveRectanglesCollision()
- I think global variables are messed up especially entity.h and client width and height. Learn how to handle.
- Add turn north west, south east and so on as actions so that it is more realistic and smooth ?
- Try functors for like Relu ?
- Add hp, stamina, weight? Is energy same as hp or stamina
- Perhaps, add eat, drink, or sociolize actions whenever he collided with entites?
- It looks like I'm having an issue with collisions, and it's called 'tunneling'.
- I dont think i need to allocate memory dynamically in zeros or in other place i use new keyword
- Consider adding the time of day as a state. Maybe I need to make environment so that it has morning and night like in real life.
- Order in FlattenState() should be fixed.
- Should I call Render() before Step() ?
- Make agent so that he can collect and use items, track its inventory, including available tools, weapons, or consumables as a state.
- Retrieve real time Japan climate/temperture from internet and add as a state.
- Learn SIMD, SOA, AOSOA
- Learn cache miss
- If he keeps energy level in 1 and certain time has passed, he will die.
- Maybe reduce energy level after certain number of time he either walk/run.
- Make entity class for each entites in RL ? like Food, Water so on, and each includes mem variables size_t flags? Instead of just using RECT
- How to make tensors lazy ?
- Enable vectorization in your compiler settings. This allows the compiler to automatically use SIMD instructions when appropriate.
- Besides SIMD, explore other compiler intrinsics for specific architectures. These can provide low-level control over certain instructions and optimizations.
- How to not or optimize dunamic allocation in Zero()
- Learn Data locality
- Actions could be diveded into various levels e.g., Eat (Low), Eat (Medium), Eat (High), Exercise (Low).
- Log fps
- maybe just use std::vector instead of float * for elem in class Tensor?

[States]
- hunger(the primary biological drive for eating is hunger, which is controlled by the hypothalamus in the brain. When the body's energy stores are depleted, signals are sent to the brain to initiate the feeling of hunger, motivating an individual to seek and consume food), thirst(dehydration or a decrease in the body's water content triggers the sensation of thirst), mental health, blood pressure, blood glucose level, fatigue, hygiene level, hair length, stress level, age, relationship, height and weight, energy level, sleepiness, health status(tooth decay, cancer, diabetes, emphysema, asthma), pain, social interactions, job satisfaction, clothing choices, emotional states, social media activity, weather conditions, temperature(日陰や雨よけ, tide), climate(wind) time of day, location, financial status (income, savings, and debt), education level, pains, feeling of goodness, news, nationality, homeostasis(such as blood sugar levels, electrolyte balance, and body temperature), emotions(such as stress, boredom, sadness, or happiness), self-esteem level(influences psychological well-being), auditory system, visual system, sense of smell, taste somatosensory system, goals(e.g., first and foremost simply survive, become leader of the group if he was a crocodile).

[Actions]
- EAT(meat, vegetable), EXERCISE, SLEEP, SOCIALIZE (talk), hydrate, work(earn money), learn, get a haircut, brush teeth, take a bath/shower, grooming, play some sports, get sun, drinking, smoking, healthcare (go to the hospital, dentist...), shop, changing careers, moving to a new location, social media, entertainment (watch movies), transportation (how to commute or travel), clean the house, drive, move stuff, digestion, reproduction(such as mating, parenting, and ensuring the survival of their offspring).

NOTE: Similar to actions, first start with 4 actions which are eat, exercise, sleep, socialize. Can perform these actions at various levels of intensity which are 3 levels (low, medium, high). In this case, it would be 3 levels for each of the 4 actions, resulting in a total of 3^4 = 81 possible action combinations.

TODO: I could go more detail e.g., 
Food Type: Specify the type of food the agent can choose to eat, such as healthy options (vegetables, fruits, lean proteins) or unhealthy options (fast food, sugary snacks).
Portion Size: Define different portion sizes (small, medium, large) for the agent's meals.
Meal Timing: Determine when the agent can eat (breakfast, lunch, dinner, snacks).

[Insights]
- Experts say the current models need 'Search system', but what it is?
- How to let him have curiosity for Science e.g., Mathematics, AI, Physics so that he will try to solve problems within these fields.
- I need to set the camera focused on him, and spawn objects e.g., food, water, possible friends, and predators etc to let him explore the environment.
- I need to save parameters such as weights, biases, and Q-table. How do you do in TF?
- Learning about why animals and human's primary purposes for living I guess making good environment might be key? If they need to adapt to environment, it needs to change over time e.g., global warming, we have to adapt to new techs.
- While primary purposes for both human and animals are driven by the principles of survival(finding food, avoiding predators, and adapting to environmental challenges(Natural selection favors traits that enhance an organism's chances of survival and reproduction in a given environment)) and reproduction. However, humans often seek additional sources of meaning and purpose. These may include personal fulfillment, relationships, contributions to society.
- All the behaviors are influenced by a combination of biological, psychological, social, and cultural factors.
- Learn how human memory works, and integrate memory for him?
- He needs to take various nutrition such as carbohydrates, proteins, fats, vitamins, and minerals through food these adequate nutrition is crucial for energy production, growth, and the maintenance and repair of bodily tissues so perhaps in the future I have to program so that not he only eats, but have to eat in good balance.
- Learn Psychology, Neuroscience, Ethology, Anthropology, Neuroethology, Sociology to get an incentive for to comprehend human behaviour.
- なぜルビーは走る
- Psychologists distinguish between extrinsic motivation, which means being moved to do something because of some specific rewarding outcome, and intrinsic motivation, which refers to being moved to do something because it is inherently enjoyable. Intrinsic motivation leads organisms to engage in exploration, play, and other behavior driven by curiosity in the absence of explicit reward. [...] Although these arguments are compelling, developmental approaches to artificial agent design have been slow to penetrate the mainstream of the machine learning community.
- an agent should address new goals forever
- Yann says RL requires insane amount of trials. How can I reduce this? He also says idea that humans and animals possess common sense, and their behavior is motivated by specific goals or objectives, which are often referred to as drives. Common sense here implies a practical understanding of the world and the ability to make decisions based on that understanding. The mention of "drives" suggests that both humans and animals are guided by their inherent needs, instincts, or motivations when determining their actions.
- use PowerPlay? https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00313/full
- consider using Entity-Component-System (ECS) in the future
- Try automatically inventing or discovering problems in a way inspired by the playful behavior of animals and humans (PowerPlay).
- Run environments the GPU instead of CPU for like multi-agent reinforcement learning (MARL) research.
- Make transpose()
- Try open-ended RL?
- Recheck if everything is properly implemented by comparing with numpy ver
- At last, actually do this in graphics
- Maybe in the future hide the food and water? As in the real nature animals have to work hard to get those rewards. e.g., crocodiles hunting zebras
- 植物はどうやって生きてる？　例、木など
- Try opengym to how real rl works
- Why I mentioned about recent news kn Kishida president? It because he’s the current president of Japan, about he reduced taxes became news on medias, Japan is in ressesion(current economic status in Japan), I was interested
- Make a global variables called is_action_up, down, left, and right will be switched in WindowsProc()
- 法に沿っていきる。
- Reference nature behaviors watching videos on YouTube.
- He has to escape from the hunters/predators.
- Draw days lived, current_state, days_without_eating, and location on the simulation screen? or create menu?
- add music to the simulation like Pokemon
- When action is set talk, set states as current situation such as holding a leaf sets alphabet as actions so that it can chose a word ‘leaf!’ Like baby would say.
- how to hide the taskbar when window is displayed?
- create class Agent?
- should other agent randomly moving? NPCs are moving in GTA, but not in Pokemon. IRL obviously people or everything is moving.   
- First create survival agent who tried to keep the life with no graphics, and maybe start off with Q-Learning.
ニャーと声を発する
- 仕切りを作る
- 俺が餌あげないと死ぬ
- 実際の時間と合わせる　while done
- the while loop never ends unless he gain great amout of rewards
- State is speak so speak up the objects in front of him before that use classification to determine what it is.
- Why do we say back ‘Hello’?
- What is considered done? Maybe it dosen't need to be done as it's not real living things which have ages.
- Get reward when successefully eaten
- First create cat like creature? Where goals are to juat live(but for how long?) and eat.
- What about creating myself e.g., wake up at the mansion, get reward when went for a walk, eaten.
- Goals (live 80 years, solve physics probs)
- Looks adult, but brain in immature. Meybe he dosen’t have to be baby might be already an adult?
- First start a goal of living 10 days by working to earn money and eat
- Goals (live 10 days, learn 10 words using nested RL)
- Earn ¥300000 per month, but can’t able to if he’s not humble enough (party too much, not living healthy enouth)
- Q-Learning -> Deep Q-Network (DQN) -> Double DQN (DDQN) -> Dueling DQN -> Deep Deterministic Policy Gradient (DDPG)
- text-based environments
- reference OpenAI's Gym (Gymnasium now?)
- Simulate the agent was born in urban city as we are.
- Can he surived meaning keep all the status as high as possible e.g., life, weight.
- maximising survival time, minimising pain, maximising healthy food, avoiding accidents
- he needs to escape from pradetors e.g., lion, crocodile so it may become injured
- How to teach him a thing is scary or cute.
- Has most recent and future goals example of former would be to go for a walk to reduce stress level, and for former will be to solve Physics problems.
- He has to educate himself to solve problems associated with Pythysics or in naturaly to survibe.
- The book 'Why Greatness Cannot Be Planned' proposes to follow the interesting and the novel instead. The authors developed an algorithm called novelty search, where instead of optimizing an objective, the agent just tries out behaviors that are as novel to it as possible, but I realized that paper 'Reward is Enough' came 6 years after this so not sure...
- While the agent interacting with the environment it should train nn for like classification tasks?
- Maybe in the future the agent can add new actions he came up with?
- Done = true if the agent found new physics theory or go to toilet or earn money ?
- Ideal plan is the agent interacts env like 2d pokemon world -> 3d pokemon or GTA world -> VR, but I guess I can accomplish the physics goal with 2d pokemon world so delete terraria idea. In 2d pokemon world add dialogues maybe using LLMs so that the agent can manipulate language which is super important. First, create one small city like the one in Pokemon?
- Add memory like using nn for classification task?
- 経済、治安、会社に就職
- Start from a baby maybe who has parents
- Starts from a house
- Get a reward if his height grew, and learned new language
- Maybe there might be RL within Rl? e.g., within the states he decide to do puzzle game in order to learn new words at this point use another RL? I mean human is also like that meaning it’s like layers of RL. In order to live, you have to work, and within the work you have to do certatin tasks.
- Start simple maybe actions would be just eat, sleep, excersise or something. I need to write a program when for example if sleep action is chose the agent has to walk up to the bed and go to bed.
- Needs body parts e.g., arms, legs.
    - Make scientific devices based on *1.
- Able to talk through audio.

- Might be in nature or urban city? It'd be fun if I could make simulation that begins with home sapines proceed to year 3000 ~ 5000, and I can steal some technologies from there.
- Might be newly born baby or animal like a monkey?
- Check Comparison of reinforcement learning algorithms on https://en.wikipedia.org/wiki/Reinforcement_learning
- also check out reinforcement learning with human feedback (RLHF) 
- First create a body in 2D resembles Stardew Valley, Terraria, pokemon. In 3D, Minecraft?
- Research and observe animals in nature.
- how childs learn to speak?
- what is Markov decision process (MDP)
- what is inverse reinforcement learning (IRL) and RHIP a new IRL algorithm?
- Imitation Learning
- online, offline learning?
- Associative reinforcement learning
- Deep reinforcement learning
- Adversarial deep reinforcement learning
- Fuzzy reinforcement learning
- Safe reinforcement learning
- knowledge, learning, perception, social intelligence, language, generalisation, imitation, and general intelligence.
- multi-objective learning, risk-sensitive objectives, or objectives that are specified by a human-in-the-loop.
- multiple agents, multiple environments?
- He looks and behaves like human being has 2 arms, legs.
- biological brains are hardwired to interpret signals such as pain and hunger as negative reinforcements, and interpret pleasure and food intake as positive reinforcements. I
- How can he act like a mosquito?
- Social intelligence is the ability to understand and interact effectively with other agents. This ability is often formalised, using game theory.
- Build human aged between 3 ~ 5.
- How to teach him words like banana actually showing banana. Not like how chatGPT is recoginising banana (predicting probable next words).
- ability to imitate
- memory, imagination, common sense, attention, reasoning, creativity
- *1 Discover new theories in Scinece, and come up with new scientific devices (Phyiscs, Mathematics, Chemistry).
Study Existing Theories - > Identify Shortcomings or Gaps - > Develop Mathematical Framework - > Make Predictions - > Seek Peer Review - > Experimental Verification - > Iterate and Refine. Can it do it?
- For example, consider a signal that provides +1 reward to the agent each time a round-shaped pebble is collected. In order to maximise this reward signal effectively, an agent may need to classify pebbles, to manipulate pebbles, to navigate to pebble beaches, to store pebbles, to understand waves and tides and their effect on pebble distribution, to persuade people to help collect pebbles, to use tools and vehicles to collect greater quantities, to quarry and shape new pebbles, to discover and build new technologies for collecting pebbles, or to build a corporation that collects pebbles.
- Able to make games from simple to AAA class.
- Play Mario game (RL).
- Conversational Agents (RL).
- unsupervised learning.
- Neuroscience
- Cognitive Science.
- Translation.
- Question- answering.
- Sentiment analysis.
- Coding.
- AlphaZero (RL).
- Content Recommendations (RL).
- Drug Discovery (RL).
- Multimodal models (CNN, LSTM, GAN).
- Eble to draw (GAN).
- Continuousness?

- I thought NLP is the core of the AGI, but it might not as the case for Computer vision, and other things like continuousness be as dogs which don't use as high level language as we do, yet behave as more high intelligent creatures better than ChatGPT. Like it is quite dumb that it dosen't know what apple is, but if I could teach RL what it is it might be able to recoginise what it is like human does.
- game theory is important?
- Get ideas from wild animal like the one in Africa.
- RL is typically not used for classification problems. It would be like trying to teach someone to recognize animals by showing them a picture of a dog, not telling them what it is, letting them guess, and then giving them a treat if they're right or a gentle admonishment if they're wrong. However, there are complex problems that have elements of both RL and classification. For example, in a robotic control problem, the robot might need to classify objects in its environment (using supervised learning) and then decide how to interact with them based on that classification (using reinforcement learning).